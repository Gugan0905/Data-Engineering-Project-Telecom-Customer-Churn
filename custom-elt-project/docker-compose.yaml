version: '3'

services:
  source_postgres:
    image: postgres:15.6
    ports:
      - "5433:5432"
    networks:
      - elt_network
    environment:
      POSTGRES_DB: source_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    volumes:
      - ./source_db_init/init-ddl.sql:/docker-entrypoint-initdb.d/init.sql

  destination_postgres:
    image: postgres:latest
    ports:
      - "5434:5432"
    networks:
      - elt_network
    environment:
      POSTGRES_DB: destination_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret

  elt_script:
    build:
      context: ./elt_script
    command: [ "python", "elt_script.py" ]
    networks:
      - elt_network
    depends_on:
      - source_postgres
      - destination_postgres
    environment:
      AWS_ACCESS_KEY_ID: "your aws acccess key"
      AWS_SECRET_ACCESS_KEY: "your aws secret key"
      AWS_DEFAULT_REGION: "your aws region"
      
  flask_app:
    build:
      context: ./flask_app
    ports:
      - "5001:5000"
    networks:
      - elt_network
    depends_on:
      - destination_postgres

  postgres:
    image: postgres:latest
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    networks:
      - elt_network


  init-airflow:
    image: apache/airflow:latest
    depends_on:
      - postgres
    networks:
      - elt_network
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: >
      bash -c "airflow db init && 
               airflow users create --username airflow --password password --firstname John --lastname Doe --role Admin --email admin@example.com"

  webserver:
    build:
      context: .
      dockerfile: Dockerfile
    user: root
    depends_on:
      - postgres
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./requirements.txt:/requirements.txt
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW_CONN_DESTINATION_POSTGRES=postgres://postgres:secret@destination_postgres:5434/destination_db
      - AIRFLOW__CORE__FERNET_KEY=AAe39qroMknqMPlYcbr7IuFNsLy95cr-toN-020K6vs=
      - AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME=airflow
      - AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD=password
      - AIRFLOW_WWW_USER_USERNAME=airflow
      - AIRFLOW_WWW_USER_PASSWORD=password
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - AWS_ACCESS_KEY_ID = "your aws access key"
      - AWS_SECRET_ACCESS_KEY = "your aws secret key"
      - AWS_DEFAULT_REGION = "your region"
    ports:
      - "8080:8080"
    command: webserver

  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    user: root
    depends_on:
      - postgres
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./requirements.txt:/requirements.txt
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW_CONN_DESTINATION_POSTGRES=postgres://postgres:secret@destination_postgres:5434/destination_db
      - AIRFLOW__CORE__FERNET_KEY=AAe39qroMknqMPlYcbr7IuFNsLy95cr-toN-020K6vs=
      - AIRFLOW_WWW_USER_USERNAME=airflow
      - AIRFLOW_WWW_USER_PASSWORD=password
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - AWS_ACCESS_KEY_ID = "your aws access key"
      - AWS_SECRET_ACCESS_KEY = "your aws secret key"
      - AWS_DEFAULT_REGION = "your region"
    command: scheduler

networks:
  elt_network:
    driver: bridge

volumes:
  destination_db_data:
